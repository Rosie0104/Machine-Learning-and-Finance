{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jandsy/ml_finance_imperial/blob/main/Coursework/CourseWork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSIsUTeyXNr_"
      },
      "source": [
        "# **<center>Machine Learning and Finance </center>**\n",
        "\n",
        "\n",
        "## <center> CourseWork 2024 - StatArb </center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests \n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBDj0uD44dQL"
      },
      "source": [
        "\n",
        "In this coursework, you will delve into and replicate selected elements of the research detailed in the paper **[End-to-End Policy Learning of a Statistical Arbitrage Autoencoder Architecture](https://arxiv.org/pdf/2402.08233.pdf)**. **However, we will not reproduce the entire study.**\n",
        "\n",
        "## Overview\n",
        "\n",
        "This study redefines Statistical Arbitrage (StatArb) by combining Autoencoder architectures and policy learning to generate trading strategies. Traditionally, StatArb involves finding the mean of a synthetic asset through classical or PCA-based methods before developing a mean reversion strategy. However, this paper proposes a data-driven approach using an Autoencoder trained on US stock returns, integrated into a neural network representing portfolio trading policies to output portfolio allocations directly.\n",
        "\n",
        "\n",
        "## Coursework Goal\n",
        "\n",
        "This coursework will replicate these results, providing hands-on experience in implementing and evaluating this innovative end-to-end policy learning Autoencoder within financial trading strategies.\n",
        "\n",
        "## Outline\n",
        "\n",
        "- [Data Preparation and Exploration](#Data-Preparation-and-Exploration)\n",
        "- [Fama French Analysis](#Fama-French-Analysis)\n",
        "- [PCA Analysis](#PCA-Analysis)\n",
        "- [Ornstein Uhlenbeck](#Ornstein-Uhlenbeck)\n",
        "- [Autoencoder Analysis](#Autoencoder-Analysis)\n",
        "\n",
        "\n",
        "\n",
        "**Description:**\n",
        "The Coursework is graded on a 100 point scale and is divided into five  parts. Below is the mark distribution for each question:\n",
        "\n",
        "| **Problem**  | **Question**          | **Number of Marks** |\n",
        "|--------------|-----------------------|---------------------|\n",
        "| **Part A**   | Question 1            | 4                   |\n",
        "|              | Question 2            | 1                   |\n",
        "|              | Question 3            | 3                   |\n",
        "|              | Question 4            | 3                   |\n",
        "|              | Question 5            | 1                   |\n",
        "|              | Question 6            | 3                   |\n",
        "|**Part  B**    | Question 7           | 1                   |\n",
        "|              | Question 8            | 5                   |\n",
        "|              | Question 9            | 4                   |\n",
        "|              | Question 10           | 5                   |\n",
        "|              | Question 11           | 2                   |\n",
        "|              | Question 12           | 3                   |\n",
        "|**Part  C**    | Question 13          | 3                   |\n",
        "|              | Question 14           | 1                   |\n",
        "|              | Question 15           | 3                   |\n",
        "|              | Question 16           | 2                   |\n",
        "|              | Question 17           | 7                   |\n",
        "|              | Question 18           | 6                   |\n",
        "|              | Question 19           | 3                   |\n",
        "|  **Part  D** | Question 20           | 3                   |\n",
        "|              | Question 21           | 5                   |\n",
        "|              | Question 22           | 2                   |\n",
        "|  **Part  E** | Question 23           | 2                   |\n",
        "|              | Question 24           | 1                   |\n",
        "|              | Question 25           | 3                   |\n",
        "|              | Question 26           | 10                  |\n",
        "|              | Question 27           | 1                   |\n",
        "|              | Question 28           | 3                   |\n",
        "|              | Question 29           | 3                   |\n",
        "|              | Question 30           | 7                   |\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Please read the questions carefully and do your best. Good luck!\n",
        "\n",
        "## Objectives\n",
        "\n",
        "\n",
        "\n",
        "## 1. Data Preparation and Exploration\n",
        "Collect, clean, and prepare US stock return data for analysis.\n",
        "\n",
        "## 2. Fama French Analysis\n",
        "Utilize Fama French Factors to isolate the idiosyncratic components of stock returns, differentiating them from market-wide effects. This analysis helps in understanding the unique characteristics of individual stocks relative to broader market trends.\n",
        "\n",
        "## 3. PCA Analysis\n",
        "Employ Principal Component Analysis (PCA) to identify hidden structures and reduce dimensionality in the data. This method helps in extracting significant patterns that might be obscured in high-dimensional datasets.\n",
        "\n",
        "## 4. Ornstein-Uhlenbeck Process\n",
        "Analyze mean-reverting behavior in stock prices using the Ornstein-Uhlenbeck process. This stochastic process is useful for modeling and forecasting based on the assumption that prices will revert to a long-term mean.\n",
        "\n",
        "## 5. Building a Basic Autoencoder Model\n",
        "Construct and train a standard Autoencoder to extract residual idiosyncratic risk.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFU9ckGplGDf"
      },
      "source": [
        "# Data Preparation and Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiqyU4DQlxsV"
      },
      "source": [
        "\n",
        "---\n",
        "<font color=green>Q1: (4 Marks)</font>\n",
        "<br><font color='green'>\n",
        "Write a Python function that accepts a URL parameter and retrieves the NASDAQ-100 companies and their ticker symbols by scraping the relevant Wikipedia page using **[Requests](https://pypi.org/project/requests/)** and **[BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)**. Your function should return the data as a list of tuples, with each tuple containing the company name and its ticker symbol. Then, call your function with the appropriate Wikipedia page URL and print the data in a 'Company: Ticker' format.\n",
        "\n",
        "</font>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lcJXF6aSxCGu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Company: Adobe Inc., Ticker: ADBE\n",
            "Company: ADP, Ticker: ADP\n",
            "Company: Airbnb, Ticker: ABNB\n",
            "Company: Alphabet Inc. (Class A), Ticker: GOOGL\n",
            "Company: Alphabet Inc. (Class C), Ticker: GOOG\n",
            "Company: Amazon, Ticker: AMZN\n",
            "Company: Advanced Micro Devices Inc., Ticker: AMD\n",
            "Company: American Electric Power, Ticker: AEP\n",
            "Company: Amgen, Ticker: AMGN\n",
            "Company: Analog Devices, Ticker: ADI\n",
            "Company: Ansys, Ticker: ANSS\n",
            "Company: Apple Inc., Ticker: AAPL\n",
            "Company: Applied Materials, Ticker: AMAT\n",
            "Company: ASML Holding, Ticker: ASML\n",
            "Company: AstraZeneca, Ticker: AZN\n",
            "Company: Atlassian, Ticker: TEAM\n",
            "Company: Autodesk, Ticker: ADSK\n",
            "Company: Baker Hughes, Ticker: BKR\n",
            "Company: Biogen, Ticker: BIIB\n",
            "Company: Booking Holdings, Ticker: BKNG\n",
            "Company: Broadcom Inc., Ticker: AVGO\n",
            "Company: Cadence Design Systems, Ticker: CDNS\n",
            "Company: CDW Corporation, Ticker: CDW\n",
            "Company: Charter Communications, Ticker: CHTR\n",
            "Company: Cintas, Ticker: CTAS\n",
            "Company: Cisco, Ticker: CSCO\n",
            "Company: Coca-Cola Europacific Partners, Ticker: CCEP\n",
            "Company: Cognizant, Ticker: CTSH\n",
            "Company: Comcast, Ticker: CMCSA\n",
            "Company: Constellation Energy, Ticker: CEG\n",
            "Company: Copart, Ticker: CPRT\n",
            "Company: CoStar Group, Ticker: CSGP\n",
            "Company: Costco, Ticker: COST\n",
            "Company: CrowdStrike, Ticker: CRWD\n",
            "Company: CSX Corporation, Ticker: CSX\n",
            "Company: Datadog, Ticker: DDOG\n",
            "Company: DexCom, Ticker: DXCM\n",
            "Company: Diamondback Energy, Ticker: FANG\n",
            "Company: Dollar Tree, Ticker: DLTR\n",
            "Company: DoorDash, Ticker: DASH\n",
            "Company: Electronic Arts, Ticker: EA\n",
            "Company: Exelon, Ticker: EXC\n",
            "Company: Fastenal, Ticker: FAST\n",
            "Company: Fortinet, Ticker: FTNT\n",
            "Company: GE HealthCare, Ticker: GEHC\n",
            "Company: Gilead Sciences, Ticker: GILD\n",
            "Company: GlobalFoundries, Ticker: GFS\n",
            "Company: Honeywell, Ticker: HON\n",
            "Company: Idexx Laboratories, Ticker: IDXX\n",
            "Company: Illumina, Inc., Ticker: ILMN\n",
            "Company: Intel, Ticker: INTC\n",
            "Company: Intuit, Ticker: INTU\n",
            "Company: Intuitive Surgical, Ticker: ISRG\n",
            "Company: Keurig Dr Pepper, Ticker: KDP\n",
            "Company: KLA Corporation, Ticker: KLAC\n",
            "Company: Kraft Heinz, Ticker: KHC\n",
            "Company: Lam Research, Ticker: LRCX\n",
            "Company: Linde plc, Ticker: LIN\n",
            "Company: Lululemon, Ticker: LULU\n",
            "Company: Marriott International, Ticker: MAR\n",
            "Company: Marvell Technology, Ticker: MRVL\n",
            "Company: MercadoLibre, Ticker: MELI\n",
            "Company: Meta Platforms, Ticker: META\n",
            "Company: Microchip Technology, Ticker: MCHP\n",
            "Company: Micron Technology, Ticker: MU\n",
            "Company: Microsoft, Ticker: MSFT\n",
            "Company: Moderna, Ticker: MRNA\n",
            "Company: Mondelēz International, Ticker: MDLZ\n",
            "Company: MongoDB Inc., Ticker: MDB\n",
            "Company: Monster Beverage, Ticker: MNST\n",
            "Company: Netflix, Ticker: NFLX\n",
            "Company: Nvidia, Ticker: NVDA\n",
            "Company: NXP, Ticker: NXPI\n",
            "Company: O'Reilly Automotive, Ticker: ORLY\n",
            "Company: Old Dominion Freight Line, Ticker: ODFL\n",
            "Company: Onsemi, Ticker: ON\n",
            "Company: Paccar, Ticker: PCAR\n",
            "Company: Palo Alto Networks, Ticker: PANW\n",
            "Company: Paychex, Ticker: PAYX\n",
            "Company: PayPal, Ticker: PYPL\n",
            "Company: PDD Holdings, Ticker: PDD\n",
            "Company: PepsiCo, Ticker: PEP\n",
            "Company: Qualcomm, Ticker: QCOM\n",
            "Company: Regeneron, Ticker: REGN\n",
            "Company: Roper Technologies, Ticker: ROP\n",
            "Company: Ross Stores, Ticker: ROST\n",
            "Company: Sirius XM, Ticker: SIRI\n",
            "Company: Starbucks, Ticker: SBUX\n",
            "Company: Synopsys, Ticker: SNPS\n",
            "Company: Take-Two Interactive, Ticker: TTWO\n",
            "Company: T-Mobile US, Ticker: TMUS\n",
            "Company: Tesla, Inc., Ticker: TSLA\n",
            "Company: Texas Instruments, Ticker: TXN\n",
            "Company: The Trade Desk, Ticker: TTD\n",
            "Company: Verisk, Ticker: VRSK\n",
            "Company: Vertex Pharmaceuticals, Ticker: VRTX\n",
            "Company: Walgreens Boots Alliance, Ticker: WBA\n",
            "Company: Warner Bros. Discovery, Ticker: WBD\n",
            "Company: Workday, Inc., Ticker: WDAY\n",
            "Company: Xcel Energy, Ticker: XEL\n",
            "Company: Zscaler, Ticker: ZS\n"
          ]
        }
      ],
      "source": [
        "def get_nasdaq_100(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
        "    rows = table.find_all('tr')[1:]  # Skip the header row\n",
        "\n",
        "    companies = []\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')\n",
        "        company = cols[0].text.strip()\n",
        "        ticker = cols[1].text.strip()\n",
        "        companies.append((company, ticker))\n",
        "\n",
        "    return companies\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/NASDAQ-100'\n",
        "companies = get_nasdaq_100(url)\n",
        "\n",
        "# Print the data in a 'Company: Ticker' format\n",
        "for company, ticker in companies:\n",
        "    print(f'Company: {company}, Ticker: {ticker}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VvyNAF9sE7u"
      },
      "source": [
        "---\n",
        "Q2: (1 Mark)\n",
        "\n",
        "Given a list of tuples representing NASDAQ-100 companies (where each tuple contains a company name and its ticker symbol), write a Python script to extract all ticker symbols into a separate list called `tickers_list`.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yQaWckkXxDLP"
      },
      "outputs": [],
      "source": [
        "tickers_list = [ticker for company, ticker in companies]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KEkAPUxsW4s"
      },
      "source": [
        "---\n",
        "Q3: (3 Marks)\n",
        "\n",
        "Using **[yfinance](https://pypi.org/project/yfinance/)** library, write a Python script that accepts a list of stock ticker symbols. For each symbol, download the adjusted closing price data, store it in a dictionary with the ticker symbol as the key, and then convert the final dictionary into a Pandas DataFrame. Handle any errors encountered during data retrieval by printing a message indicating which symbol failed\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pynohwbpxEg5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n",
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "def get_adjusted_close_prices(tickers):\n",
        "    data_dict = {}\n",
        "    for ticker in tickers:\n",
        "        try:\n",
        "            data = yf.download(ticker, start='2000-01-01', end='2024-05-21')\n",
        "            data_dict[ticker] = data['Adj Close']\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download data for {ticker}. Reason: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(data_dict)\n",
        "    return df\n",
        "\n",
        "df = get_adjusted_close_prices(tickers_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADP</th>\n",
              "      <th>ABNB</th>\n",
              "      <th>GOOGL</th>\n",
              "      <th>GOOG</th>\n",
              "      <th>AMZN</th>\n",
              "      <th>AMD</th>\n",
              "      <th>AEP</th>\n",
              "      <th>AMGN</th>\n",
              "      <th>ADI</th>\n",
              "      <th>...</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>TXN</th>\n",
              "      <th>TTD</th>\n",
              "      <th>VRSK</th>\n",
              "      <th>VRTX</th>\n",
              "      <th>WBA</th>\n",
              "      <th>WBD</th>\n",
              "      <th>WDAY</th>\n",
              "      <th>XEL</th>\n",
              "      <th>ZS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-01-03</th>\n",
              "      <td>16.274672</td>\n",
              "      <td>24.781528</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.468750</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>10.773263</td>\n",
              "      <td>44.925060</td>\n",
              "      <td>28.438284</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.968735</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.781250</td>\n",
              "      <td>17.076204</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.977996</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-04</th>\n",
              "      <td>14.909400</td>\n",
              "      <td>24.781528</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.096875</td>\n",
              "      <td>14.625000</td>\n",
              "      <td>10.901772</td>\n",
              "      <td>41.489872</td>\n",
              "      <td>26.999632</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.566660</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.281250</td>\n",
              "      <td>16.440989</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.138672</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-05</th>\n",
              "      <td>15.204174</td>\n",
              "      <td>24.543242</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.487500</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>11.308716</td>\n",
              "      <td>42.917492</td>\n",
              "      <td>27.393780</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.805527</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>16.627823</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.414119</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-06</th>\n",
              "      <td>15.328286</td>\n",
              "      <td>24.870886</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.278125</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>11.372970</td>\n",
              "      <td>43.631294</td>\n",
              "      <td>26.644884</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.964285</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.750000</td>\n",
              "      <td>16.142059</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.345260</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-01-07</th>\n",
              "      <td>16.072985</td>\n",
              "      <td>25.436808</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.478125</td>\n",
              "      <td>16.250000</td>\n",
              "      <td>11.522890</td>\n",
              "      <td>48.538692</td>\n",
              "      <td>27.393780</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.124537</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.218750</td>\n",
              "      <td>16.553080</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.345260</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-14</th>\n",
              "      <td>475.950012</td>\n",
              "      <td>245.500000</td>\n",
              "      <td>146.699997</td>\n",
              "      <td>170.339996</td>\n",
              "      <td>171.929993</td>\n",
              "      <td>187.070007</td>\n",
              "      <td>153.160004</td>\n",
              "      <td>90.790001</td>\n",
              "      <td>309.213806</td>\n",
              "      <td>211.940002</td>\n",
              "      <td>...</td>\n",
              "      <td>177.550003</td>\n",
              "      <td>191.130005</td>\n",
              "      <td>86.180000</td>\n",
              "      <td>246.929993</td>\n",
              "      <td>428.589996</td>\n",
              "      <td>18.097662</td>\n",
              "      <td>8.56</td>\n",
              "      <td>246.880005</td>\n",
              "      <td>55.560001</td>\n",
              "      <td>176.820007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-15</th>\n",
              "      <td>485.350006</td>\n",
              "      <td>246.619995</td>\n",
              "      <td>145.800003</td>\n",
              "      <td>172.509995</td>\n",
              "      <td>173.880005</td>\n",
              "      <td>185.990005</td>\n",
              "      <td>159.669998</td>\n",
              "      <td>91.970001</td>\n",
              "      <td>316.790009</td>\n",
              "      <td>215.750000</td>\n",
              "      <td>...</td>\n",
              "      <td>173.990005</td>\n",
              "      <td>195.529999</td>\n",
              "      <td>90.250000</td>\n",
              "      <td>247.839996</td>\n",
              "      <td>437.489990</td>\n",
              "      <td>17.643988</td>\n",
              "      <td>8.20</td>\n",
              "      <td>251.309998</td>\n",
              "      <td>55.790001</td>\n",
              "      <td>181.130005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-16</th>\n",
              "      <td>482.880005</td>\n",
              "      <td>250.059998</td>\n",
              "      <td>147.190002</td>\n",
              "      <td>174.179993</td>\n",
              "      <td>175.429993</td>\n",
              "      <td>183.630005</td>\n",
              "      <td>162.619995</td>\n",
              "      <td>92.540001</td>\n",
              "      <td>314.720001</td>\n",
              "      <td>214.119995</td>\n",
              "      <td>...</td>\n",
              "      <td>174.839996</td>\n",
              "      <td>194.970001</td>\n",
              "      <td>93.190002</td>\n",
              "      <td>251.479996</td>\n",
              "      <td>440.640015</td>\n",
              "      <td>18.087799</td>\n",
              "      <td>8.23</td>\n",
              "      <td>256.570007</td>\n",
              "      <td>55.849998</td>\n",
              "      <td>179.309998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-17</th>\n",
              "      <td>483.429993</td>\n",
              "      <td>252.330002</td>\n",
              "      <td>145.660004</td>\n",
              "      <td>176.059998</td>\n",
              "      <td>177.289993</td>\n",
              "      <td>184.699997</td>\n",
              "      <td>164.470001</td>\n",
              "      <td>92.669998</td>\n",
              "      <td>312.470001</td>\n",
              "      <td>214.080002</td>\n",
              "      <td>...</td>\n",
              "      <td>177.460007</td>\n",
              "      <td>195.020004</td>\n",
              "      <td>94.779999</td>\n",
              "      <td>251.619995</td>\n",
              "      <td>445.209991</td>\n",
              "      <td>17.930000</td>\n",
              "      <td>8.05</td>\n",
              "      <td>257.929993</td>\n",
              "      <td>55.520000</td>\n",
              "      <td>178.860001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-20</th>\n",
              "      <td>484.690002</td>\n",
              "      <td>251.779999</td>\n",
              "      <td>146.369995</td>\n",
              "      <td>176.919998</td>\n",
              "      <td>178.460007</td>\n",
              "      <td>183.539993</td>\n",
              "      <td>166.330002</td>\n",
              "      <td>92.589996</td>\n",
              "      <td>314.540009</td>\n",
              "      <td>217.479996</td>\n",
              "      <td>...</td>\n",
              "      <td>174.949997</td>\n",
              "      <td>199.199997</td>\n",
              "      <td>97.500000</td>\n",
              "      <td>252.410004</td>\n",
              "      <td>445.869995</td>\n",
              "      <td>17.820000</td>\n",
              "      <td>8.09</td>\n",
              "      <td>259.500000</td>\n",
              "      <td>56.070000</td>\n",
              "      <td>180.600006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6134 rows × 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ADBE         ADP        ABNB       GOOGL        GOOG  \\\n",
              "Date                                                                     \n",
              "2000-01-03   16.274672   24.781528         NaN         NaN         NaN   \n",
              "2000-01-04   14.909400   24.781528         NaN         NaN         NaN   \n",
              "2000-01-05   15.204174   24.543242         NaN         NaN         NaN   \n",
              "2000-01-06   15.328286   24.870886         NaN         NaN         NaN   \n",
              "2000-01-07   16.072985   25.436808         NaN         NaN         NaN   \n",
              "...                ...         ...         ...         ...         ...   \n",
              "2024-05-14  475.950012  245.500000  146.699997  170.339996  171.929993   \n",
              "2024-05-15  485.350006  246.619995  145.800003  172.509995  173.880005   \n",
              "2024-05-16  482.880005  250.059998  147.190002  174.179993  175.429993   \n",
              "2024-05-17  483.429993  252.330002  145.660004  176.059998  177.289993   \n",
              "2024-05-20  484.690002  251.779999  146.369995  176.919998  178.460007   \n",
              "\n",
              "                  AMZN         AMD        AEP        AMGN         ADI  ...  \\\n",
              "Date                                                                   ...   \n",
              "2000-01-03    4.468750   15.500000  10.773263   44.925060   28.438284  ...   \n",
              "2000-01-04    4.096875   14.625000  10.901772   41.489872   26.999632  ...   \n",
              "2000-01-05    3.487500   15.000000  11.308716   42.917492   27.393780  ...   \n",
              "2000-01-06    3.278125   16.000000  11.372970   43.631294   26.644884  ...   \n",
              "2000-01-07    3.478125   16.250000  11.522890   48.538692   27.393780  ...   \n",
              "...                ...         ...        ...         ...         ...  ...   \n",
              "2024-05-14  187.070007  153.160004  90.790001  309.213806  211.940002  ...   \n",
              "2024-05-15  185.990005  159.669998  91.970001  316.790009  215.750000  ...   \n",
              "2024-05-16  183.630005  162.619995  92.540001  314.720001  214.119995  ...   \n",
              "2024-05-17  184.699997  164.470001  92.669998  312.470001  214.080002  ...   \n",
              "2024-05-20  183.539993  166.330002  92.589996  314.540009  217.479996  ...   \n",
              "\n",
              "                  TSLA         TXN        TTD        VRSK        VRTX  \\\n",
              "Date                                                                    \n",
              "2000-01-03         NaN   32.968735        NaN         NaN   18.781250   \n",
              "2000-01-04         NaN   31.566660        NaN         NaN   17.281250   \n",
              "2000-01-05         NaN   30.805527        NaN         NaN   17.000000   \n",
              "2000-01-06         NaN   29.964285        NaN         NaN   16.750000   \n",
              "2000-01-07         NaN   30.124537        NaN         NaN   18.218750   \n",
              "...                ...         ...        ...         ...         ...   \n",
              "2024-05-14  177.550003  191.130005  86.180000  246.929993  428.589996   \n",
              "2024-05-15  173.990005  195.529999  90.250000  247.839996  437.489990   \n",
              "2024-05-16  174.839996  194.970001  93.190002  251.479996  440.640015   \n",
              "2024-05-17  177.460007  195.020004  94.779999  251.619995  445.209991   \n",
              "2024-05-20  174.949997  199.199997  97.500000  252.410004  445.869995   \n",
              "\n",
              "                  WBA   WBD        WDAY        XEL          ZS  \n",
              "Date                                                            \n",
              "2000-01-03  17.076204   NaN         NaN   6.977996         NaN  \n",
              "2000-01-04  16.440989   NaN         NaN   7.138672         NaN  \n",
              "2000-01-05  16.627823   NaN         NaN   7.414119         NaN  \n",
              "2000-01-06  16.142059   NaN         NaN   7.345260         NaN  \n",
              "2000-01-07  16.553080   NaN         NaN   7.345260         NaN  \n",
              "...               ...   ...         ...        ...         ...  \n",
              "2024-05-14  18.097662  8.56  246.880005  55.560001  176.820007  \n",
              "2024-05-15  17.643988  8.20  251.309998  55.790001  181.130005  \n",
              "2024-05-16  18.087799  8.23  256.570007  55.849998  179.309998  \n",
              "2024-05-17  17.930000  8.05  257.929993  55.520000  178.860001  \n",
              "2024-05-20  17.820000  8.09  259.500000  56.070000  180.600006  \n",
              "\n",
              "[6134 rows x 101 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# save the data to a csv file\n",
        "df.to_csv('nasdaq_100_data.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np3XHMtatQC_"
      },
      "source": [
        "---\n",
        "<font color=green>Q4: (3 Marks)</font>\n",
        "<br><font color='green'>\n",
        "Write a Python script to analyze stock data stored in a dictionary `stock_data` (where each key is a stock ticker symbol, and each value is a Pandas Series of adjusted closing prices). The script should:\n",
        "1. Convert the dictionary into a DataFrame.\n",
        "2. Calculate the daily returns for each stock.\n",
        "3. Identify columns (ticker symbols) with at least 2000 non-NaN values in their daily returns.\n",
        "4. Create a new DataFrame that only includes these filtered ticker symbols.\n",
        "5. Remove any remaining rows with NaN values in this new DataFrame.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "2pt3y9_IxFjz"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADP</th>\n",
              "      <th>GOOGL</th>\n",
              "      <th>GOOG</th>\n",
              "      <th>AMZN</th>\n",
              "      <th>AMD</th>\n",
              "      <th>AEP</th>\n",
              "      <th>AMGN</th>\n",
              "      <th>ADI</th>\n",
              "      <th>ANSS</th>\n",
              "      <th>...</th>\n",
              "      <th>TTWO</th>\n",
              "      <th>TMUS</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>TXN</th>\n",
              "      <th>VRSK</th>\n",
              "      <th>VRTX</th>\n",
              "      <th>WBA</th>\n",
              "      <th>WBD</th>\n",
              "      <th>WDAY</th>\n",
              "      <th>XEL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-12-10</th>\n",
              "      <td>-0.006699</td>\n",
              "      <td>0.006004</td>\n",
              "      <td>-0.003292</td>\n",
              "      <td>-0.002861</td>\n",
              "      <td>-0.003715</td>\n",
              "      <td>0.042553</td>\n",
              "      <td>-0.024355</td>\n",
              "      <td>0.011274</td>\n",
              "      <td>0.008826</td>\n",
              "      <td>0.004968</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004777</td>\n",
              "      <td>0.007485</td>\n",
              "      <td>0.011358</td>\n",
              "      <td>0.002995</td>\n",
              "      <td>-0.002616</td>\n",
              "      <td>0.010279</td>\n",
              "      <td>0.000960</td>\n",
              "      <td>-0.002109</td>\n",
              "      <td>0.005037</td>\n",
              "      <td>-0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-11</th>\n",
              "      <td>0.027653</td>\n",
              "      <td>-0.024924</td>\n",
              "      <td>-0.012657</td>\n",
              "      <td>-0.014130</td>\n",
              "      <td>-0.033473</td>\n",
              "      <td>-0.036735</td>\n",
              "      <td>-0.005831</td>\n",
              "      <td>-0.028308</td>\n",
              "      <td>-0.003849</td>\n",
              "      <td>-0.013951</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011575</td>\n",
              "      <td>-0.009356</td>\n",
              "      <td>-0.044259</td>\n",
              "      <td>-0.012647</td>\n",
              "      <td>-0.015995</td>\n",
              "      <td>-0.034709</td>\n",
              "      <td>-0.020499</td>\n",
              "      <td>-0.035928</td>\n",
              "      <td>-0.057630</td>\n",
              "      <td>0.004311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-14</th>\n",
              "      <td>0.020127</td>\n",
              "      <td>0.015240</td>\n",
              "      <td>0.016151</td>\n",
              "      <td>0.012045</td>\n",
              "      <td>0.027744</td>\n",
              "      <td>-0.008475</td>\n",
              "      <td>-0.000367</td>\n",
              "      <td>0.019078</td>\n",
              "      <td>-0.001932</td>\n",
              "      <td>0.003899</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005141</td>\n",
              "      <td>0.014444</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.014390</td>\n",
              "      <td>-0.016491</td>\n",
              "      <td>0.010403</td>\n",
              "      <td>-0.033613</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>0.010017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-15</th>\n",
              "      <td>0.008149</td>\n",
              "      <td>0.010284</td>\n",
              "      <td>-0.003213</td>\n",
              "      <td>-0.005844</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>0.008547</td>\n",
              "      <td>0.027503</td>\n",
              "      <td>0.028525</td>\n",
              "      <td>-0.004752</td>\n",
              "      <td>0.009544</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023018</td>\n",
              "      <td>0.044907</td>\n",
              "      <td>0.011483</td>\n",
              "      <td>0.023657</td>\n",
              "      <td>0.013923</td>\n",
              "      <td>0.013656</td>\n",
              "      <td>-0.005450</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>0.007935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-12-16</th>\n",
              "      <td>0.016380</td>\n",
              "      <td>0.008541</td>\n",
              "      <td>0.021708</td>\n",
              "      <td>0.019761</td>\n",
              "      <td>0.026008</td>\n",
              "      <td>0.076271</td>\n",
              "      <td>0.017309</td>\n",
              "      <td>0.012053</td>\n",
              "      <td>0.017330</td>\n",
              "      <td>0.008354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006389</td>\n",
              "      <td>0.025419</td>\n",
              "      <td>0.060699</td>\n",
              "      <td>0.009036</td>\n",
              "      <td>0.021116</td>\n",
              "      <td>0.010658</td>\n",
              "      <td>0.031664</td>\n",
              "      <td>0.024887</td>\n",
              "      <td>0.029378</td>\n",
              "      <td>0.023896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-14</th>\n",
              "      <td>-0.014821</td>\n",
              "      <td>-0.009282</td>\n",
              "      <td>0.007095</td>\n",
              "      <td>0.006027</td>\n",
              "      <td>0.002680</td>\n",
              "      <td>0.017269</td>\n",
              "      <td>-0.007976</td>\n",
              "      <td>0.009596</td>\n",
              "      <td>0.017084</td>\n",
              "      <td>-0.007130</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007016</td>\n",
              "      <td>-0.005755</td>\n",
              "      <td>0.032928</td>\n",
              "      <td>0.017623</td>\n",
              "      <td>0.002395</td>\n",
              "      <td>-0.003117</td>\n",
              "      <td>0.012693</td>\n",
              "      <td>0.021480</td>\n",
              "      <td>-0.000809</td>\n",
              "      <td>-0.004836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-15</th>\n",
              "      <td>0.019750</td>\n",
              "      <td>0.004562</td>\n",
              "      <td>0.012739</td>\n",
              "      <td>0.011342</td>\n",
              "      <td>-0.005773</td>\n",
              "      <td>0.042505</td>\n",
              "      <td>0.012997</td>\n",
              "      <td>0.024502</td>\n",
              "      <td>0.017977</td>\n",
              "      <td>0.012337</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021523</td>\n",
              "      <td>0.001662</td>\n",
              "      <td>-0.020051</td>\n",
              "      <td>0.023021</td>\n",
              "      <td>0.003685</td>\n",
              "      <td>0.020766</td>\n",
              "      <td>-0.025068</td>\n",
              "      <td>-0.042056</td>\n",
              "      <td>0.017944</td>\n",
              "      <td>0.004140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-16</th>\n",
              "      <td>-0.005089</td>\n",
              "      <td>0.013949</td>\n",
              "      <td>0.009681</td>\n",
              "      <td>0.008914</td>\n",
              "      <td>-0.012689</td>\n",
              "      <td>0.018476</td>\n",
              "      <td>0.006198</td>\n",
              "      <td>-0.006534</td>\n",
              "      <td>-0.007555</td>\n",
              "      <td>-0.007124</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.013506</td>\n",
              "      <td>0.005532</td>\n",
              "      <td>0.004885</td>\n",
              "      <td>-0.002864</td>\n",
              "      <td>0.014687</td>\n",
              "      <td>0.007200</td>\n",
              "      <td>0.025154</td>\n",
              "      <td>0.003659</td>\n",
              "      <td>0.020930</td>\n",
              "      <td>0.001075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-17</th>\n",
              "      <td>0.001139</td>\n",
              "      <td>0.009078</td>\n",
              "      <td>0.010793</td>\n",
              "      <td>0.010603</td>\n",
              "      <td>0.005827</td>\n",
              "      <td>0.011376</td>\n",
              "      <td>0.001405</td>\n",
              "      <td>-0.007149</td>\n",
              "      <td>-0.000187</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012048</td>\n",
              "      <td>0.002568</td>\n",
              "      <td>0.014985</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.000557</td>\n",
              "      <td>0.010371</td>\n",
              "      <td>-0.008724</td>\n",
              "      <td>-0.021871</td>\n",
              "      <td>0.005301</td>\n",
              "      <td>-0.005909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-05-20</th>\n",
              "      <td>0.002606</td>\n",
              "      <td>-0.002180</td>\n",
              "      <td>0.004885</td>\n",
              "      <td>0.006599</td>\n",
              "      <td>-0.006280</td>\n",
              "      <td>0.011309</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>0.006625</td>\n",
              "      <td>0.015882</td>\n",
              "      <td>0.002685</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020698</td>\n",
              "      <td>-0.000610</td>\n",
              "      <td>-0.014144</td>\n",
              "      <td>0.021434</td>\n",
              "      <td>0.003140</td>\n",
              "      <td>0.001482</td>\n",
              "      <td>-0.006135</td>\n",
              "      <td>0.004969</td>\n",
              "      <td>0.006087</td>\n",
              "      <td>0.009906</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2124 rows × 89 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                ADBE       ADP     GOOGL      GOOG      AMZN       AMD  \\\n",
              "Date                                                                     \n",
              "2015-12-10 -0.006699  0.006004 -0.003292 -0.002861 -0.003715  0.042553   \n",
              "2015-12-11  0.027653 -0.024924 -0.012657 -0.014130 -0.033473 -0.036735   \n",
              "2015-12-14  0.020127  0.015240  0.016151  0.012045  0.027744 -0.008475   \n",
              "2015-12-15  0.008149  0.010284 -0.003213 -0.005844  0.001110  0.008547   \n",
              "2015-12-16  0.016380  0.008541  0.021708  0.019761  0.026008  0.076271   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2024-05-14 -0.014821 -0.009282  0.007095  0.006027  0.002680  0.017269   \n",
              "2024-05-15  0.019750  0.004562  0.012739  0.011342 -0.005773  0.042505   \n",
              "2024-05-16 -0.005089  0.013949  0.009681  0.008914 -0.012689  0.018476   \n",
              "2024-05-17  0.001139  0.009078  0.010793  0.010603  0.005827  0.011376   \n",
              "2024-05-20  0.002606 -0.002180  0.004885  0.006599 -0.006280  0.011309   \n",
              "\n",
              "                 AEP      AMGN       ADI      ANSS  ...      TTWO      TMUS  \\\n",
              "Date                                                ...                       \n",
              "2015-12-10 -0.024355  0.011274  0.008826  0.004968  ... -0.004777  0.007485   \n",
              "2015-12-11 -0.005831 -0.028308 -0.003849 -0.013951  ... -0.011575 -0.009356   \n",
              "2015-12-14 -0.000367  0.019078 -0.001932  0.003899  ...  0.005141  0.014444   \n",
              "2015-12-15  0.027503  0.028525 -0.004752  0.009544  ...  0.023018  0.044907   \n",
              "2015-12-16  0.017309  0.012053  0.017330  0.008354  ...  0.006389  0.025419   \n",
              "...              ...       ...       ...       ...  ...       ...       ...   \n",
              "2024-05-14 -0.007976  0.009596  0.017084 -0.007130  ...  0.007016 -0.005755   \n",
              "2024-05-15  0.012997  0.024502  0.017977  0.012337  ...  0.021523  0.001662   \n",
              "2024-05-16  0.006198 -0.006534 -0.007555 -0.007124  ... -0.013506  0.005532   \n",
              "2024-05-17  0.001405 -0.007149 -0.000187  0.000550  ...  0.012048  0.002568   \n",
              "2024-05-20 -0.000863  0.006625  0.015882  0.002685  ...  0.020698 -0.000610   \n",
              "\n",
              "                TSLA       TXN      VRSK      VRTX       WBA       WBD  \\\n",
              "Date                                                                     \n",
              "2015-12-10  0.011358  0.002995 -0.002616  0.010279  0.000960 -0.002109   \n",
              "2015-12-11 -0.044259 -0.012647 -0.015995 -0.034709 -0.020499 -0.035928   \n",
              "2015-12-14  0.007188  0.000178  0.014390 -0.016491  0.010403 -0.033613   \n",
              "2015-12-15  0.011483  0.023657  0.013923  0.013656 -0.005450  0.002646   \n",
              "2015-12-16  0.060699  0.009036  0.021116  0.010658  0.031664  0.024887   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2024-05-14  0.032928  0.017623  0.002395 -0.003117  0.012693  0.021480   \n",
              "2024-05-15 -0.020051  0.023021  0.003685  0.020766 -0.025068 -0.042056   \n",
              "2024-05-16  0.004885 -0.002864  0.014687  0.007200  0.025154  0.003659   \n",
              "2024-05-17  0.014985  0.000256  0.000557  0.010371 -0.008724 -0.021871   \n",
              "2024-05-20 -0.014144  0.021434  0.003140  0.001482 -0.006135  0.004969   \n",
              "\n",
              "                WDAY       XEL  \n",
              "Date                            \n",
              "2015-12-10  0.005037 -0.013889  \n",
              "2015-12-11 -0.057630  0.004311  \n",
              "2015-12-14  0.000253  0.010017  \n",
              "2015-12-15 -0.000380  0.007935  \n",
              "2015-12-16  0.029378  0.023896  \n",
              "...              ...       ...  \n",
              "2024-05-14 -0.000809 -0.004836  \n",
              "2024-05-15  0.017944  0.004140  \n",
              "2024-05-16  0.020930  0.001075  \n",
              "2024-05-17  0.005301 -0.005909  \n",
              "2024-05-20  0.006087  0.009906  \n",
              "\n",
              "[2124 rows x 89 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def analyze_stock_data(stock_data):\n",
        "\n",
        "    stock_df = pd.DataFrame(stock_data)\n",
        "    daily_returns = stock_df.pct_change()\n",
        "    valid_columns = daily_returns.columns[daily_returns.count() >= 2000]\n",
        "    filtered_df = daily_returns[valid_columns]\n",
        "    cleaned_df = filtered_df.dropna()\n",
        "\n",
        "    return cleaned_df\n",
        "\n",
        "stock_data = df.to_dict(orient='series')\n",
        "cleaned_data = analyze_stock_data(stock_data)\n",
        "cleaned_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3xAawJ8nPbH"
      },
      "source": [
        "---\n",
        "<font color=green>Q5: (1 Mark)</font>\n",
        "<br><font color='green'>\n",
        "Download the dataset named `df_filtered_nasdaq_100` from the GitHub repository of the course.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Ko4juu_HxHnT"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>ADBE</th>\n",
              "      <th>ADP</th>\n",
              "      <th>GOOGL</th>\n",
              "      <th>GOOG</th>\n",
              "      <th>AMZN</th>\n",
              "      <th>AMD</th>\n",
              "      <th>AEP</th>\n",
              "      <th>AMGN</th>\n",
              "      <th>ADI</th>\n",
              "      <th>...</th>\n",
              "      <th>TTWO</th>\n",
              "      <th>TMUS</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>TXN</th>\n",
              "      <th>VRSK</th>\n",
              "      <th>VRTX</th>\n",
              "      <th>WBA</th>\n",
              "      <th>WBD</th>\n",
              "      <th>WDAY</th>\n",
              "      <th>XEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-12-10</td>\n",
              "      <td>-0.006699</td>\n",
              "      <td>0.006004</td>\n",
              "      <td>-0.003292</td>\n",
              "      <td>-0.002861</td>\n",
              "      <td>-0.003715</td>\n",
              "      <td>0.042553</td>\n",
              "      <td>-0.024356</td>\n",
              "      <td>0.011274</td>\n",
              "      <td>0.008826</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004777</td>\n",
              "      <td>0.007485</td>\n",
              "      <td>0.011358</td>\n",
              "      <td>0.002996</td>\n",
              "      <td>-0.002616</td>\n",
              "      <td>0.010279</td>\n",
              "      <td>0.000960</td>\n",
              "      <td>-0.002109</td>\n",
              "      <td>0.005037</td>\n",
              "      <td>-0.013889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-12-11</td>\n",
              "      <td>0.027653</td>\n",
              "      <td>-0.024924</td>\n",
              "      <td>-0.012657</td>\n",
              "      <td>-0.014130</td>\n",
              "      <td>-0.033473</td>\n",
              "      <td>-0.036735</td>\n",
              "      <td>-0.005831</td>\n",
              "      <td>-0.028308</td>\n",
              "      <td>-0.003850</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011575</td>\n",
              "      <td>-0.009356</td>\n",
              "      <td>-0.044259</td>\n",
              "      <td>-0.012648</td>\n",
              "      <td>-0.015996</td>\n",
              "      <td>-0.034709</td>\n",
              "      <td>-0.020499</td>\n",
              "      <td>-0.035928</td>\n",
              "      <td>-0.057630</td>\n",
              "      <td>0.004311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-12-14</td>\n",
              "      <td>0.020127</td>\n",
              "      <td>0.015241</td>\n",
              "      <td>0.016151</td>\n",
              "      <td>0.012045</td>\n",
              "      <td>0.027744</td>\n",
              "      <td>-0.008475</td>\n",
              "      <td>-0.000366</td>\n",
              "      <td>0.019078</td>\n",
              "      <td>-0.001932</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005141</td>\n",
              "      <td>0.014444</td>\n",
              "      <td>0.007188</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.014390</td>\n",
              "      <td>-0.016491</td>\n",
              "      <td>0.010402</td>\n",
              "      <td>-0.033613</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>0.010017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-12-15</td>\n",
              "      <td>0.008149</td>\n",
              "      <td>0.010283</td>\n",
              "      <td>-0.003213</td>\n",
              "      <td>-0.005844</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>0.008547</td>\n",
              "      <td>0.027503</td>\n",
              "      <td>0.028525</td>\n",
              "      <td>-0.004752</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023018</td>\n",
              "      <td>0.044907</td>\n",
              "      <td>0.011483</td>\n",
              "      <td>0.023657</td>\n",
              "      <td>0.013923</td>\n",
              "      <td>0.013656</td>\n",
              "      <td>-0.005450</td>\n",
              "      <td>0.002646</td>\n",
              "      <td>-0.000380</td>\n",
              "      <td>0.007934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-12-16</td>\n",
              "      <td>0.016380</td>\n",
              "      <td>0.008541</td>\n",
              "      <td>0.021708</td>\n",
              "      <td>0.019761</td>\n",
              "      <td>0.026008</td>\n",
              "      <td>0.076271</td>\n",
              "      <td>0.017309</td>\n",
              "      <td>0.012053</td>\n",
              "      <td>0.017330</td>\n",
              "      <td>...</td>\n",
              "      <td>0.006389</td>\n",
              "      <td>0.025419</td>\n",
              "      <td>0.060699</td>\n",
              "      <td>0.009036</td>\n",
              "      <td>0.021117</td>\n",
              "      <td>0.010658</td>\n",
              "      <td>0.031664</td>\n",
              "      <td>0.024887</td>\n",
              "      <td>0.029378</td>\n",
              "      <td>0.023897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2113</th>\n",
              "      <td>2024-05-06</td>\n",
              "      <td>0.015241</td>\n",
              "      <td>0.003514</td>\n",
              "      <td>0.005142</td>\n",
              "      <td>0.004971</td>\n",
              "      <td>0.013372</td>\n",
              "      <td>0.034396</td>\n",
              "      <td>0.002370</td>\n",
              "      <td>-0.037939</td>\n",
              "      <td>0.018484</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016863</td>\n",
              "      <td>-0.013548</td>\n",
              "      <td>0.019703</td>\n",
              "      <td>0.015427</td>\n",
              "      <td>0.019087</td>\n",
              "      <td>0.003540</td>\n",
              "      <td>-0.030881</td>\n",
              "      <td>-0.001255</td>\n",
              "      <td>-0.022949</td>\n",
              "      <td>0.002028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2114</th>\n",
              "      <td>2024-05-07</td>\n",
              "      <td>-0.002674</td>\n",
              "      <td>0.009805</td>\n",
              "      <td>0.018739</td>\n",
              "      <td>0.018548</td>\n",
              "      <td>0.000318</td>\n",
              "      <td>-0.008666</td>\n",
              "      <td>0.011936</td>\n",
              "      <td>0.002738</td>\n",
              "      <td>0.001230</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000067</td>\n",
              "      <td>-0.001109</td>\n",
              "      <td>-0.037616</td>\n",
              "      <td>0.012752</td>\n",
              "      <td>0.021252</td>\n",
              "      <td>0.019230</td>\n",
              "      <td>0.005214</td>\n",
              "      <td>-0.023869</td>\n",
              "      <td>-0.001921</td>\n",
              "      <td>0.012141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2115</th>\n",
              "      <td>2024-05-08</td>\n",
              "      <td>-0.008471</td>\n",
              "      <td>-0.008894</td>\n",
              "      <td>-0.010920</td>\n",
              "      <td>-0.010521</td>\n",
              "      <td>-0.004026</td>\n",
              "      <td>-0.005245</td>\n",
              "      <td>0.007900</td>\n",
              "      <td>0.023343</td>\n",
              "      <td>0.006337</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015910</td>\n",
              "      <td>0.003946</td>\n",
              "      <td>-0.017378</td>\n",
              "      <td>0.007007</td>\n",
              "      <td>-0.009838</td>\n",
              "      <td>0.020915</td>\n",
              "      <td>-0.006916</td>\n",
              "      <td>0.003861</td>\n",
              "      <td>0.000802</td>\n",
              "      <td>-0.001636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2116</th>\n",
              "      <td>2024-05-09</td>\n",
              "      <td>-0.011166</td>\n",
              "      <td>0.009097</td>\n",
              "      <td>0.003424</td>\n",
              "      <td>0.002454</td>\n",
              "      <td>0.007979</td>\n",
              "      <td>-0.008007</td>\n",
              "      <td>0.004085</td>\n",
              "      <td>0.018060</td>\n",
              "      <td>-0.000342</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001987</td>\n",
              "      <td>0.011361</td>\n",
              "      <td>-0.015739</td>\n",
              "      <td>0.007448</td>\n",
              "      <td>0.001676</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>0.001161</td>\n",
              "      <td>0.030769</td>\n",
              "      <td>-0.014702</td>\n",
              "      <td>0.005644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2117</th>\n",
              "      <td>2024-05-10</td>\n",
              "      <td>-0.000746</td>\n",
              "      <td>0.006975</td>\n",
              "      <td>-0.007708</td>\n",
              "      <td>-0.007518</td>\n",
              "      <td>-0.010660</td>\n",
              "      <td>-0.003084</td>\n",
              "      <td>0.007257</td>\n",
              "      <td>-0.008662</td>\n",
              "      <td>0.011719</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001373</td>\n",
              "      <td>-0.002915</td>\n",
              "      <td>-0.020352</td>\n",
              "      <td>0.009335</td>\n",
              "      <td>0.013593</td>\n",
              "      <td>0.009046</td>\n",
              "      <td>-0.003478</td>\n",
              "      <td>0.013682</td>\n",
              "      <td>0.001545</td>\n",
              "      <td>0.003983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2118 rows × 90 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date      ADBE       ADP     GOOGL      GOOG      AMZN       AMD  \\\n",
              "0     2015-12-10 -0.006699  0.006004 -0.003292 -0.002861 -0.003715  0.042553   \n",
              "1     2015-12-11  0.027653 -0.024924 -0.012657 -0.014130 -0.033473 -0.036735   \n",
              "2     2015-12-14  0.020127  0.015241  0.016151  0.012045  0.027744 -0.008475   \n",
              "3     2015-12-15  0.008149  0.010283 -0.003213 -0.005844  0.001110  0.008547   \n",
              "4     2015-12-16  0.016380  0.008541  0.021708  0.019761  0.026008  0.076271   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "2113  2024-05-06  0.015241  0.003514  0.005142  0.004971  0.013372  0.034396   \n",
              "2114  2024-05-07 -0.002674  0.009805  0.018739  0.018548  0.000318 -0.008666   \n",
              "2115  2024-05-08 -0.008471 -0.008894 -0.010920 -0.010521 -0.004026 -0.005245   \n",
              "2116  2024-05-09 -0.011166  0.009097  0.003424  0.002454  0.007979 -0.008007   \n",
              "2117  2024-05-10 -0.000746  0.006975 -0.007708 -0.007518 -0.010660 -0.003084   \n",
              "\n",
              "           AEP      AMGN       ADI  ...      TTWO      TMUS      TSLA  \\\n",
              "0    -0.024356  0.011274  0.008826  ... -0.004777  0.007485  0.011358   \n",
              "1    -0.005831 -0.028308 -0.003850  ... -0.011575 -0.009356 -0.044259   \n",
              "2    -0.000366  0.019078 -0.001932  ...  0.005141  0.014444  0.007188   \n",
              "3     0.027503  0.028525 -0.004752  ...  0.023018  0.044907  0.011483   \n",
              "4     0.017309  0.012053  0.017330  ...  0.006389  0.025419  0.060699   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2113  0.002370 -0.037939  0.018484  ...  0.016863 -0.013548  0.019703   \n",
              "2114  0.011936  0.002738  0.001230  ... -0.000067 -0.001109 -0.037616   \n",
              "2115  0.007900  0.023343  0.006337  ... -0.015910  0.003946 -0.017378   \n",
              "2116  0.004085  0.018060 -0.000342  ... -0.001987  0.011361 -0.015739   \n",
              "2117  0.007257 -0.008662  0.011719  ...  0.001373 -0.002915 -0.020352   \n",
              "\n",
              "           TXN      VRSK      VRTX       WBA       WBD      WDAY       XEL  \n",
              "0     0.002996 -0.002616  0.010279  0.000960 -0.002109  0.005037 -0.013889  \n",
              "1    -0.012648 -0.015996 -0.034709 -0.020499 -0.035928 -0.057630  0.004311  \n",
              "2     0.000178  0.014390 -0.016491  0.010402 -0.033613  0.000253  0.010017  \n",
              "3     0.023657  0.013923  0.013656 -0.005450  0.002646 -0.000380  0.007934  \n",
              "4     0.009036  0.021117  0.010658  0.031664  0.024887  0.029378  0.023897  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "2113  0.015427  0.019087  0.003540 -0.030881 -0.001255 -0.022949  0.002028  \n",
              "2114  0.012752  0.021252  0.019230  0.005214 -0.023869 -0.001921  0.012141  \n",
              "2115  0.007007 -0.009838  0.020915 -0.006916  0.003861  0.000802 -0.001636  \n",
              "2116  0.007448  0.001676  0.000406  0.001161  0.030769 -0.014702  0.005644  \n",
              "2117  0.009335  0.013593  0.009046 -0.003478  0.013682  0.001545  0.003983  \n",
              "\n",
              "[2118 rows x 90 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('df_filtered_nasdaq_100.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WbCUDabWQoZ"
      },
      "source": [
        "---\n",
        "<font color=green>Q6: (3 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Conduct an in-depth analysis of the `df_filtered_nasdaq_100` dataset from GitHub. Answer the following questions:\n",
        "- Which stock had the best performance over the entire period?\n",
        "- What is the average daily return of 'AAPL'?\n",
        "- What is the worst daily return? Provide the stock name and the date it occurred.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock with the best performance over the entire period: MNST , Best performance value: 1191.734069081319\n",
            "Average daily return of AAPL: 0.0011996403192543487\n",
            "The worst daily return was -0.5655690229383197 by REGN on 2003-03-31 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# 1. Which stock had the best performance over the entire period?\n",
        "# Calculate the total return for each stock\n",
        "total_returns = (df.iloc[-1] / df.iloc[0]) - 1\n",
        "best_performance_stock = total_returns.idxmax()\n",
        "best_performance_value = total_returns.max()\n",
        "print(\"Stock with the best performance over the entire period:\", best_performance_stock, \", Best performance value:\", best_performance_value)\n",
        "\n",
        "# 2. What is the average daily return of 'AAPL'?\n",
        "daily_returns = df.pct_change()\n",
        "average_daily_return_aapl = daily_returns['AAPL'].mean()\n",
        "print(\"Average daily return of AAPL:\", average_daily_return_aapl)\n",
        "\n",
        "# 3. What is the worst daily return? Provide the stock name and the date it occurred.\n",
        "worst_return = daily_returns.min().min()\n",
        "worst_stock = daily_returns.min().idxmin()\n",
        "worst_date = daily_returns[daily_returns == worst_return].stack().index.tolist()[0][0]\n",
        "print(f\"The worst daily return was {worst_return} by {worst_stock} on {worst_date}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcY-V82zXGqc"
      },
      "source": [
        "# Fama French Analysis\n",
        "\n",
        "The Fama-French five-factor model is an extension of the classic three-factor model used in finance to describe stock returns. It is designed to better capture the risk associated with stocks and explain differences in returns. This model includes the following factors:\n",
        "\n",
        "1. **Market Risk (MKT)**: The excess return of the market over the risk-free rate. It captures the overall market's premium.\n",
        "2. **Size (SMB, \"Small Minus Big\")**: The performance of small-cap stocks relative to large-cap stocks.\n",
        "3. **Value (HML, \"High Minus Low\")**: The performance of stocks with high book-to-market values relative to those with low book-to-market values.\n",
        "4. **Profitability (RMW, \"Robust Minus Weak\")**: The difference in returns between companies with robust (high) and weak (low) profitability.\n",
        "5. **Investment (CMA, \"Conservative Minus Aggressive\")**: The difference in returns between companies that invest conservatively and those that invest aggressively.\n",
        "\n",
        "## Additional Factor\n",
        "\n",
        "6. **Momentum (MOM)**: This factor represents the tendency of stocks that have performed well in the past to continue performing well, and the reverse for stocks that have performed poorly.\n",
        "\n",
        "### Mathematical Representation\n",
        "\n",
        "The return of a stock $R_i^t$ at time $t$ can be modeled as follows :\n",
        "\n",
        "$$\n",
        "R_i^t - R_f^t = \\alpha_i^t + \\beta_{i,MKT}^t(R_M^t - R_f^t) + \\beta_{i,SMB}^t \\cdot SMB^t + \\beta_{i,HML}^t \\cdot HML^t + \\beta_{i,RMW}^t \\cdot RMW^t + \\beta_{i,CMA}^t \\cdot CMA^t + \\beta_{i,MOM}^t \\cdot MOM^t + \\epsilon_i^t\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ R_i^t $ is the return of stock $i$ at time $t$\n",
        "- $R_f^t $is the risk-free rate at time $t$\n",
        "- $ R_M^t $ is the market return at time $t$\n",
        "- $\\alpha_i^t $ is the abnormal return or alpha of stock $ i $ at time $t$\n",
        "- $\\beta^t $ coefficients represent the sensitivity of the stock returns to each factor at time $t$\n",
        "- $\\epsilon_i^t $ is the error term or idiosyncratic risk unique to stock $ i $ at time $t$\n",
        "\n",
        "This model is particularly useful for identifying which factors significantly impact stock returns and for constructing a diversified portfolio that is optimized for given risk preferences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtFgmpsKQc8B"
      },
      "source": [
        "---\n",
        "<font color=green>Q7: (1 Mark) </font>\n",
        "<br><font color='green'>\n",
        "Download the `fama_french_dataset` from the course's GitHub account.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "iJVPHhTSxKuk"
      },
      "outputs": [],
      "source": [
        "fama = pd.read_csv(\"fama_french_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5FJ362KW-wh"
      },
      "source": [
        "---\n",
        "<font color=green>Q8: (5 Marks)</font>\n",
        "<br><font color='green'>\n",
        "\n",
        "Write a Python function called `get_sub_df_ticker(ticker, date, df_filtered, length_history)` that extracts a historical sub-dataframe for a given `ticker` from `df_filtered`. The function should use `length_history` to determine the number of trading days to include, ending at the specified `date`. Return the sub-dataframe for the specified `ticker`.\n",
        "</font>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mIrS_fpxLsR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-p7nCNYXYNr"
      },
      "source": [
        "---\n",
        "<font color=green>Q9: (4 Marks)</font>\n",
        "<br><font color='green'>\n",
        "Create a Python function named `df_ticker_with_fama_french(ticker, date, df_filtered, length_history, fama_french_data)` that uses `get_sub_df_ticker` to extract historical data for a specific `ticker`. Incorporate the Fama-French factors from `fama_french_data` into the extracted sub-dataframe. Adjust the ticker's returns by subtracting the risk-free rate ('RF') and add other relevant Fama-French factors ('Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', and 'Mom'). Return the resulting sub-dataframe.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfsdj79HxMnp"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykVqmW4PQe5T"
      },
      "source": [
        "---\n",
        "<font color=green>Q10: (5 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Write a Python function named `extract_beta_fama_french` to perform a rolling regression analysis for a given stock at a specific time point using the Fama-French model. The function should accept the following parameters:\n",
        "\n",
        "- `ticker`: A string indicating the stock symbol.\n",
        "- `date`: A string specifying the date for the analysis.\n",
        "- `length_history`: An integer representing the number of days of historical data to include.\n",
        "- `df_filtered`: A pandas DataFrame (assumed to be derived from question 5) containing filtered stock data.\n",
        "- `fama_french_data`: A pandas DataFrame (assumed to be from question 7) that includes Fama-French factors.\n",
        "\n",
        "Utilize the `statsmodels.api` library to conduct the regression.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGSUB3UDxN2B"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY8FqrBjRDTz"
      },
      "source": [
        "---\n",
        "<font color=green>Q11: (2 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Apply the `extract_beta_fama_french` function to the stock symbol 'AAPL' for the date '2024-03-28', using a historical data length of 252 days. Ensure that the `df_filtered` and `fama_french_data` DataFrames are correctly prepared and available in your environment before executing this function. The parameters for the function call are set as follows:\n",
        "\n",
        "- **Ticker**: 'AAPL'\n",
        "- **Date**: '2024-03-28'\n",
        "- **Length of History**: 252 days\n",
        "</font>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fo6C5-qXxPZO"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DyA4G1d0HjY"
      },
      "source": [
        "---\n",
        "<font color=green>Q12: (2 Marks)</font>\n",
        "<br><font color='green'>\n",
        "Once the `extract_beta_fama_french` function has been applied to 'AAPL' with the specified parameters, the next step is to analyze the regression summary to identify which Fama-French factor explains the most variance in 'AAPL' returns during the specified period.\n",
        "\n",
        "Follow these steps to perform the analysis:\n",
        "\n",
        "1. **Review the Summary**: Examine the regression output, focusing on the coefficients and their statistical significance (p-values).\n",
        "2. **Identify Key Factor**: Determine which factor has the highest absolute coefficient value and is statistically significant (typically p < 0.05). This factor can be considered as having the strongest influence on 'AAPL' returns for the period.\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thaIsaiFWWNO"
      },
      "source": [
        "**Write your answers here:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj7qlAq-J8N2"
      },
      "source": [
        "# PCA Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qty6V05YXxti"
      },
      "source": [
        "\n",
        "In literature, another method exists for extracting residuals for each stock, utilizing the PCA approach to identify hidden factors in the data. Let's describe this method.\n",
        "\n",
        "The return of a stock $R_i^t$ at time $t$ can be modeled as follows :\n",
        "\n",
        "$$\n",
        "R_i^t  = \\sum_{j=1}^m\\beta_{i,j}^t F_j^t  + \\epsilon_i^t\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ R_i^t $ is the return of stock $i$ at time $t$\n",
        "- $m$ is the number of factors selected from PCA\n",
        "-  $ F_j^t $ is the $j$-th hidden factor constructed from PCA at time $t$\n",
        "- $\\beta_{i,j}^t $ are the coefficients representing the sensitivity of the stock returns to each hidden factor.\n",
        "- $\\epsilon_i^t $  is the residual term for stock $i$ at time $t$, representing the portion of the return not explained by the PCA factors.\n",
        "\n",
        "### Representation of Stock Return Data\n",
        "\n",
        "Consider the return data for $N$ stocks over $T$ periods, represented by the matrix $R$ of size $T \\times N$:\n",
        "\n",
        "$$\n",
        "R = \\left[\n",
        "\\begin{array}{cccc}\n",
        "R_1^T & R_2^T & \\cdots & R_N^T \\\\\n",
        "R_1^{T-1} & R_2^{T-1} & \\cdots & R_N^{T-1} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "R_1^1 & R_2^1 & \\cdots & R_N^1 \\\\\n",
        "\\end{array}\n",
        "\\right]\n",
        "$$\n",
        "\n",
        "Each element $R_i^k$ of the matrix represents the return of stock $i$ at time $k$ and is defined as:\n",
        "\n",
        "$$\n",
        "R_i^k = \\frac{S_{i,k} - S_{i, k-1}}{S_{i, k-1}}, \\quad k=1,\\cdots, T, \\quad i=1,\\cdots,N\n",
        "$$\n",
        "\n",
        "where $S_{i,k}$ denotes the adjusted close price of stock $i$ at time $k$.\n",
        "\n",
        "### Standardization of Returns\n",
        "\n",
        "To adjust for varying volatilities across stocks, we standardize the returns as follows:\n",
        "\n",
        "$$\n",
        "Z_i^t = \\frac{R_i^t - \\mu_i}{\\sigma_i}\n",
        "$$\n",
        "\n",
        "where $\\mu_i$ and $\\sigma_i$ are the mean and standard deviation of returns for stock $i$ over the period $[t-T, t]$, respectively.\n",
        "\n",
        "### Empirical Correlation Matrix\n",
        "\n",
        "The empirical correlation matrix $C$ is computed from the standardized returns:\n",
        "\n",
        "$$\n",
        "C = \\frac{1}{T-1} Z^T Z\n",
        "$$\n",
        "\n",
        "where $Z^T$ is the transpose of matrix $Z$.\n",
        "\n",
        "### Singular Value Decomposition (SVD)\n",
        "\n",
        "We apply Singular Value Decomposition to the correlation matrix $C$:\n",
        "\n",
        "$$\n",
        "C = U \\Sigma V^T\n",
        "$$\n",
        "\n",
        "Here, $U$ and $V$ are orthogonal matrices representing the left and right singular vectors, respectively, and $\\Sigma$ is a diagonal matrix containing the singular values, which are the square roots of the eigenvalues.\n",
        "\n",
        "### Construction of Hidden Factors\n",
        "\n",
        "For each of the top $m$ components, we construct the selected hidden factors as follows:\n",
        "\n",
        "$$\n",
        "F_j^t = \\sum_{i=1}^N \\frac{\\lambda_{i,j}}{\\sigma_i} R_i^t\n",
        "$$\n",
        "\n",
        "where $\\lambda_{i,j}$ is the $i$-th component of the $j$-th eigenvector (ranked by eigenvalue magnitude).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIkNjUbFZ3Wy"
      },
      "source": [
        "---\n",
        "<font color=green>Q13 (3 Marks):\n",
        "\n",
        "For the specified period from March 29, 2023 ('2023-03-29'), to March 28, 2024 ('2024-03-28'), generate the matrix $Z$ by standardizing the stock returns using the DataFrame `df_filtered_new`\n",
        "</font>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqhmrY9xcbnk"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quv2tOhXch4-"
      },
      "source": [
        "---\n",
        "<font color=green>Q14: (1 Mark) </font>\n",
        "<br><font color='green'>\n",
        "Download the `Z_matrix` matrix from the course's GitHub account.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmSz-J_oxYQa"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d-2MrrzatMc"
      },
      "source": [
        "---\n",
        "<font color=green>Q15: (3 Marks) </font>\n",
        "<br><font color='green'>\n",
        "For the specified period from March 29, 2023 ('2023-03-29'), to March 28, 2024 ('2024-03-28'), compute the correlation matrix\n",
        "$C$ using the matrix `Z_matrix`.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rRt-HL1xZqA"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FnUvUEkjAbG"
      },
      "source": [
        "---\n",
        "<font color=green>Q16: (2 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Refind the correlation matrix from the from March 29, 2023 ('2023-03-29'), to March 28, 2024 ('2024-03-28') using pandas correlation matrix method.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_g-VjITxasb"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvsiMvgfaxzW"
      },
      "source": [
        "---\n",
        "<font color=green>Q17: (7 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Conduct Singular Value Decomposition on the correlation matrix $C$. Follow these steps:\n",
        "\n",
        "\n",
        "1.   **Perform SVD**: Decompose the matrix $C$ into its singular values and vectors.\n",
        "2.   **Rank Eigenvalues**: Sort the resulting singular values (often squared to compare to eigenvalues) in descending order.\n",
        "3. **Select Components**: Extract the first 20 components based on the largest singular values.\n",
        "4. **Variance Explained**: Print the variance explained by the first 20 Components and dimensions of differents matrix that you created.\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pohRSmSExbkq"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3sZ7K-Tb6S_"
      },
      "source": [
        "---\n",
        "<font color=green>Q18: (6 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Extract the 20 hidden factors in a matrix F. Check that shape of F is $(252,20)$\n",
        "</font>\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzT32wMixcjq"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz-ncrUmCAVW"
      },
      "source": [
        "---\n",
        "<font color=green>Q19: (3 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Perform the Regression Analysis of 'AAPL' for the date '2024-03-28', using a historical data length of 252 days using previous $F$ Matrix. Compare the R-squared from the ones obtained at Q11.\n",
        "</font>\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcPG6YWoxdgn"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDU8xmpi_ueR"
      },
      "source": [
        "# Ornstein Uhlenbeck\n",
        "\n",
        "The Ornstein-Uhlenbeck process is defined by the following stochastic differential equation (SDE):\n",
        "\n",
        "$$ dX_t = \\theta (\\mu - X_t) dt + \\sigma dW_t $$\n",
        "\n",
        "where:\n",
        "\n",
        "- **$ X_t $**: The value of the process at time $ t $.\n",
        "- **$ \\mu $**: The long-term mean (equilibrium level) to which the process reverts.\n",
        "- **$ \\theta $**: The speed of reversion or the rate at which the process returns to the mean.\n",
        "- **$ \\sigma $**: The volatility (standard deviation), representing the magnitude of random fluctuations.\n",
        "- **$ W_t $**: A Wiener process or Brownian motion that adds stochastic (random) noise.\n",
        "\n",
        "This equation describes a process where the variable $ X_t $ moves towards the mean $ \\mu $ at a rate determined by $ \\theta $, with random noise added by $ \\sigma dW_t $."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HMYOiWsP53c"
      },
      "source": [
        "---\n",
        "<font color=green>Q20: (3 Marks) </font>\n",
        "<br><font color='green'>\n",
        "In the context of mean reversion, which quantity should be modeled using an Ornstein-Uhlenbeck process?\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiO01w7fO_bR"
      },
      "source": [
        "**Write your answers here:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t31Q2iWgQgsO"
      },
      "source": [
        "---\n",
        "<font color=green>Q21: (5 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Explain how the parameters $ \\theta $ and $ \\sigma $ can be determined using the following equations. Also, detail the underlying assumptions:\n",
        "$$ E[X] = \\mu $$\n",
        "$$ \\text{Var}[X] = \\frac{\\sigma^2}{2\\theta} $$\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_KjMbQplj4U"
      },
      "source": [
        "**Write your answers here:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JvTPsTTSMp4"
      },
      "source": [
        "---\n",
        "<font color=green>Q22: (2 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Create a function named `extract_s_scores` which computes 's scores' for the last element in a list of floating-point numbers. This function calculates the scores using the following formula $ \\text{s scores} = \\frac{X_T - \\mu}{\\sigma} $ where `list_xi` represents a list containing a sequence of floating-point numbers $(X_0, \\cdots, X_T)$.\n",
        "\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unNHgTj8xkv5"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAB_ANF2gCiY"
      },
      "source": [
        "# Autoencoder Analysis\n",
        "\n",
        "Autoencoders are neural networks used for unsupervised learning, particularly for dimensionality reduction and feature extraction. Training an autoencoder on the $Z_i$ matrix aims to identify hidden factors capturing the intrinsic structures in financial data.\n",
        "\n",
        "### Architecture\n",
        "- **Encoder**: Compresses input data into a smaller latent space representation.\n",
        "  - *Input Layer*: Matches the number of features in the $Z_i$ matrix.\n",
        "  - *Hidden Layers*: Compress data through progressively smaller layers.\n",
        "  - *Latent Space*: Encodes the data into hidden factors.\n",
        "- **Decoder**: Reconstructs input data from the latent space.\n",
        "  - *Hidden Layers*: Gradually expand to the original dimension.\n",
        "  - *Output Layer*: Matches the input layer to recreate the original matrix.\n",
        "\n",
        "### Training\n",
        "The autoencoder is trained by minimizing reconstruction loss, usually mean squared error (MSE), between the input $Z_i$ matrix and the decoder's output.\n",
        "\n",
        "### Hidden Factors Extraction\n",
        "After training, the encoder's latent space provides the most important underlying patterns in the stock returns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJzNtknXgdqF"
      },
      "source": [
        "---\n",
        "<font color=green>Q23: (2 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Modify the standardized returns matrix `Z_matrix` to reduce the influence of extreme outliers on model trainingby ensuring that all values in the matrix `Z_matrix` do not exceed 3 standard deviations from the mean. Specifically, cap these values at the interval $-3, 3]$. Store the adjusted values in a new matrix, `Z_hat`.\n",
        "</font>\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln7vWV0TxmFk"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNJDLYZ9g_V4"
      },
      "source": [
        "---\n",
        "<font color=green>Q24: (1 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Fetch the `Z_hat` data from GitHub, and we'll proceed with it now.\n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BraH_nivxngd"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3MRBtXIiWcN"
      },
      "source": [
        "---\n",
        "<font color=green>Q25: (3 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Segment the standardized and capped returns matrix $\\hat{Z}$ into two subsets for model training and testing. Precisly Allocate 70% of the data in $\\hat{Z}$ to the training set $ \\hat{Z}_{train} $ and Allocate the remaining 30% to the testing set $\\hat{Z}_{test}$. Treat each stock within $\\hat{Z}$ as an individual sample, by flattening temporal dependencies.\n",
        "</font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ggdgu_3wxobS"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqWeD_efihbH"
      },
      "source": [
        "---\n",
        "<font color=green>Q26: (10 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Please create an autoencoder following the instructions provided in  **[End-to-End Policy Learning of a Statistical Arbitrage Autoencoder Architecture](https://arxiv.org/pdf/2402.08233.pdf)**, Use the model 'Variant 2' in Table 1.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyf_dfsoxp_X"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6o0QBPateR"
      },
      "source": [
        "---\n",
        "<font color=green>Q27 (1 Mark) :\n",
        "\n",
        "Display all the parameters of the deep neural network.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLyuzLkGxrAd"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lNBOw3ait03"
      },
      "source": [
        "---\n",
        "<font color=green>Q28: (3 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Train your model using the Adam optimizer for 20 epochs with a batch size equal to 8 and validation split to 20%. Specify the loss function you've chosen.\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBUtUlxIxsrx"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xI8O24djAYO"
      },
      "source": [
        "---\n",
        "<font color=green>Q29: (3 Marks) </font>\n",
        "<br><font color='green'>\n",
        "Predict using the testing set and extract the residuals based on the methodology described in **[End-to-End Policy Learning of a Statistical Arbitrage Autoencoder Architecture](https://arxiv.org/pdf/2402.08233.pdf)**.\n",
        "for 'NVDA' stock.\n",
        "</font>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-EDTK7wxtxB"
      },
      "outputs": [],
      "source": [
        "## Insert your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYyVOZu90CIK"
      },
      "source": [
        "<font color=green>Q30: (7 Marks) </font>\n",
        "<br><font color='green'>\n",
        "By reading carrefully the paper **[End-to-End Policy Learning of a Statistical Arbitrage Autoencoder Architecture](https://arxiv.org/pdf/2402.08233.pdf)**, answers the following question:\n",
        "1. **Summarize the Key Actions**: Highlight the main experiments and methodologies employed by the authors in Section 5.\n",
        "2. **Reproduction Steps**: Detail the necessary steps required to replicate the authors' approach based on the descriptions provided in the paper.\n",
        "3. **Proposed Improvement**: Suggest one potential enhancement to the methodology that could potentially increase the effectiveness or efficiency of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na95zQB40hRG"
      },
      "source": [
        "**Write your answers here:**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
